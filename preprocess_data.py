"""
æ•°æ®é¢„å¤„ç†è„šæœ¬
ç”¨äºæ¸…æ´—å’Œå‡†å¤‡è®­ç»ƒæ•°æ®
"""
import json
from collections import defaultdict
from datetime import datetime

INPUT_FILE = "twitter_training_data.jsonl"
OUTPUT_FILE = "cleaned_data.jsonl"


def load_data(filename):
    """åŠ è½½ JSONL æ•°æ®"""
    records = []
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                try:
                    record = json.loads(line.strip())
                    records.append(record)
                except json.JSONDecodeError as e:
                    print(f"âš ï¸  è¡Œ {line_num} JSON è§£æé”™è¯¯: {e}")
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
        return []

    return records


def clean_data(records):
    """æ•°æ®æ¸…æ´—"""
    print("\nğŸ“‹ å¼€å§‹æ•°æ®æ¸…æ´—...")

    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total': len(records),
        'duplicates': 0,
        'empty_input': 0,
        'invalid_output': 0,
        'errors': 0
    }

    # å»é‡ - åŸºäº input å†…å®¹
    seen = set()
    cleaned = []

    # æŒ‰æ ‡ç­¾åˆ†ç±»ç»Ÿè®¡
    label_counts = defaultdict(int)

    for record in records:
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        if not record.get('input'):
            stats['empty_input'] += 1
            continue

        # å»é‡
        input_text = record['input']
        if input_text in seen:
            stats['duplicates'] += 1
            continue

        # éªŒè¯ output æ ¼å¼
        try:
            output_data = json.loads(record.get('output', '{}'))

            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
            if output_data.get('error', False):
                stats['errors'] += 1
                continue

            # æ£€æŸ¥å¿…è¦å­—æ®µ
            if 'rhetoric_score' not in output_data or 'manipulation_score' not in output_data:
                stats['invalid_output'] += 1
                continue

            # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
            label = output_data.get('label', 'unknown')
            label_counts[label] += 1

        except json.JSONDecodeError:
            stats['invalid_output'] += 1
            continue

        seen.add(input_text)
        cleaned.append(record)

    print(f"âœ… åŸå§‹è®°å½•: {stats['total']}")
    print(f"âŒ ç§»é™¤é‡å¤: {stats['duplicates']}")
    print(f"âŒ ç§»é™¤ç©ºè¾“å…¥: {stats['empty_input']}")
    print(f"âŒ ç§»é™¤æ— æ•ˆè¾“å‡º: {stats['invalid_output']}")
    print(f"âŒ ç§»é™¤é”™è¯¯è®°å½•: {stats['errors']}")
    print(f"âœ… æ¸…æ´—åè®°å½•: {len(cleaned)}")

    print(f"\nğŸ“Š æ ‡ç­¾åˆ†å¸ƒ:")
    for label, count in sorted(label_counts.items(), key=lambda x: x[1], reverse=True):
        percentage = (count / len(cleaned)) * 100 if cleaned else 0
        print(f"  {label}: {count} ({percentage:.1f}%)")

    return cleaned


def save_data(records, filename):
    """ä¿å­˜æ¸…æ´—åçš„æ•°æ®"""
    with open(filename, 'w', encoding='utf-8') as f:
        for record in records:
            f.write(json.dumps(record, ensure_ascii=False) + '\n')
    print(f"\nğŸ’¾ å·²ä¿å­˜è‡³: {filename}")


def analyze_scores(records):
    """åˆ†æåˆ†æ•°åˆ†å¸ƒ"""
    print("\nğŸ“ˆ åˆ†æ•°åˆ†å¸ƒåˆ†æ:")

    rhetoric_scores = []
    manipulation_scores = []

    for record in records:
        try:
            output = json.loads(record['output'])
            rhetoric_scores.append(output.get('rhetoric_score', 0))
            manipulation_scores.append(output.get('manipulation_score', 0))
        except:
            continue

    if rhetoric_scores:
        print(f"\nä¿®è¾å¯†åº¦ (Rhetoric Score):")
        print(f"  å¹³å‡å€¼: {sum(rhetoric_scores) / len(rhetoric_scores):.2f}")
        print(f"  æœ€å°å€¼: {min(rhetoric_scores)}")
        print(f"  æœ€å¤§å€¼: {max(rhetoric_scores)}")
        print(f"  ä¸­ä½æ•°: {sorted(rhetoric_scores)[len(rhetoric_scores)//2]}")

    if manipulation_scores:
        print(f"\næ“çºµæŒ‡æ•° (Manipulation Score):")
        print(f"  å¹³å‡å€¼: {sum(manipulation_scores) / len(manipulation_scores):.2f}")
        print(f"  æœ€å°å€¼: {min(manipulation_scores)}")
        print(f"  æœ€å¤§å€¼: {max(manipulation_scores)}")
        print(f"  ä¸­ä½æ•°: {sorted(manipulation_scores)[len(manipulation_scores)//2]}")

    # é£é™©ç­‰çº§åˆ†å¸ƒ
    risk_levels = defaultdict(int)
    for r, m in zip(rhetoric_scores, manipulation_scores):
        max_score = max(r, m)
        if max_score >= 8:
            risk_levels['é«˜é£é™©'] += 1
        elif max_score >= 5:
            risk_levels['ä¸­é£é™©'] += 1
        else:
            risk_levels['ä½é£é™©'] += 1

    print(f"\né£é™©ç­‰çº§åˆ†å¸ƒ:")
    for level, count in risk_levels.items():
        percentage = (count / len(rhetoric_scores)) * 100 if rhetoric_scores else 0
        print(f"  {level}: {count} ({percentage:.1f}%)")


def main():
    print("=" * 60)
    print("ğŸ” Rhetoric Lens æ•°æ®é¢„å¤„ç†å·¥å…·")
    print("=" * 60)

    # åŠ è½½æ•°æ®
    records = load_data(INPUT_FILE)
    if not records:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ’ä»¶æ”¶é›†æ•°æ®")
        return

    # æ¸…æ´—æ•°æ®
    cleaned = clean_data(records)

    if not cleaned:
        print("âŒ æ¸…æ´—åæ²¡æœ‰æœ‰æ•ˆæ•°æ®")
        return

    # åˆ†æåˆ†æ•°åˆ†å¸ƒ
    analyze_scores(cleaned)

    # ä¿å­˜æ¸…æ´—åçš„æ•°æ®
    save_data(cleaned, OUTPUT_FILE)

    print("\n" + "=" * 60)
    print("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
    print(f"ğŸ’¡ ä¸‹ä¸€æ­¥: ä½¿ç”¨ {OUTPUT_FILE} è¿›è¡Œæ¨¡å‹è®­ç»ƒ")
    print("=" * 60)


if __name__ == "__main__":
    main()
