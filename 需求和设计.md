这是一个非常棒的 MVP（最小可行性产品）场景！将“隐性”的模型推理能力转换为前端“显性”的视觉辅助，是展示 AI 落地能力的最佳方式。

我们将构建一个 Chrome 扩展，包含以下核心逻辑：

1. **监听器 (Observer):** 监控网页滚动（针对 Twitter/X 这种动态加载页面），发现新推文。
2. **提取器 (Extractor):** 抓取推文文本。
3. **分析器 (Analyzer):** 调用你的 Mac Mini/云端 API。
4. **渲染器 (Renderer):** 在推文旁插入一个色块（Badge），鼠标悬停显示 tooltip。

---

### 项目结构

请在本地创建一个文件夹 `rhetoric-detector-extension`，并在其中创建以下 4 个文件：

```text
rhetoric-detector-extension/
├── manifest.json   # 配置文件
├── content.js      # 核心逻辑脚本
├── styles.css      # 样式表
└── icon.png        # (可选) 找个 128x128 的图片放进去

```

---

### 1. `manifest.json` (配置清单)

这是 Chrome 插件的身份证。我们声明它可以在推特（x.com）上运行。

```json
{
  "manifest_version": 3,
  "name": "Rhetoric Lens - 舆论透镜",
  "version": "1.0",
  "description": "分析推文的修辞密度与操纵指数",
  "permissions": ["activeTab", "scripting"],
  "host_permissions": [
    "https://x.com/*", 
    "http://localhost:11434/*",
    "https://api.yourdomain.com/*" 
  ],
  "content_scripts": [
    {
      "matches": ["https://x.com/*"],
      "js": ["content.js"],
      "css": ["styles.css"]
    }
  ]
}

```

### 2. `styles.css` (视觉样式)

定义色块和悬浮提示框（Tooltip）的样式。

```css
/* 评分色块 Badge */
.ai-badge {
    display: inline-flex;
    align-items: center;
    justify-content: center;
    padding: 4px 8px;
    margin-left: 10px;
    border-radius: 6px;
    font-size: 12px;
    font-weight: bold;
    color: white;
    cursor: help;
    position: relative;
    box-shadow: 0 2px 4px rgba(0,0,0,0.2);
    transition: transform 0.2s;
    user-select: none;
}

.ai-badge:hover {
    transform: scale(1.05);
}

/* 悬浮提示框 Tooltip */
.ai-tooltip {
    visibility: hidden;
    width: 250px;
    background-color: #333;
    color: #fff;
    text-align: left;
    border-radius: 6px;
    padding: 10px;
    position: absolute;
    z-index: 9999;
    bottom: 125%; /* 显示在上方 */
    left: 50%;
    transform: translateX(-50%);
    opacity: 0;
    transition: opacity 0.3s;
    font-size: 12px;
    line-height: 1.4;
    box-shadow: 0 4px 6px rgba(0,0,0,0.3);
    pointer-events: none;
}

.ai-tooltip::after {
    content: "";
    position: absolute;
    top: 100%;
    left: 50%;
    margin-left: -5px;
    border-width: 5px;
    border-style: solid;
    border-color: #333 transparent transparent transparent;
}

.ai-badge:hover .ai-tooltip {
    visibility: visible;
    opacity: 1;
}

/* 颜色等级 */
.score-safe { background-color: #10B981; } /* 绿色 */
.score-warning { background-color: #F59E0B; } /* 橙色 */
.score-danger { background-color: #EF4444; } /* 红色 */

```

### 3. `content.js` (核心逻辑)

这里是魔术发生的地方。我们需要处理 Twitter 复杂的 DOM 结构和动态加载。

```javascript
// 配置你的 API 地址 (可以是 localhost 或 Cloudflare 域名)
const API_ENDPOINT = "http://localhost:11434/api/chat"; 
const MODEL_NAME = "xiuci-pro"; // 你之前 create 的模型名

// 缓存已处理的推文，防止重复分析
const processedTweets = new Set();

// 1. 颜色判断逻辑
function getColorClass(rhetoric, manipulation) {
    const maxScore = Math.max(rhetoric, manipulation);
    if (maxScore >= 8) return "score-danger";
    if (maxScore >= 5) return "score-warning";
    return "score-safe";
}

// 2. 调用 LLM 进行分析
async function analyzeText(text) {
    try {
        const response = await fetch(API_ENDPOINT, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
                model: MODEL_NAME,
                messages: [{ role: "user", content: text }],
                format: "json", // 强制 JSON 模式
                stream: false
            })
        });

        const data = await response.json();
        // Ollama 返回的 content 是字符串，需要再 parse 一次
        return JSON.parse(data.message.content);
    } catch (error) {
        console.error("AI 分析失败:", error);
        return null;
    }
}

// 3. 创建 UI 组件
function createBadge(result) {
    const badge = document.createElement("div");
    const colorClass = getColorClass(result.rhetoric_score, result.manipulation_score);
    
    badge.className = `ai-badge ${colorClass}`;
    badge.innerHTML = `
        R:${result.rhetoric_score} | M:${result.manipulation_score}
        <div class="ai-tooltip">
            <strong>类型:</strong> ${result.label}<br/>
            <strong>理由:</strong> ${result.reason}
        </div>
    `;
    return badge;
}

// 4. 处理单条推文
async function processTweet(tweetElement) {
    // 找到推文文本内容 (Twitter 的 class 是乱码，用 data-testid 最稳)
    const textNode = tweetElement.querySelector('[data-testid="tweetText"]');
    if (!textNode) return;

    const text = textNode.innerText;
    // 简单去重 (生产环境可以用 hash)
    if (processedTweets.has(text)) return; 
    processedTweets.add(text);

    // 插入一个 "分析中..." 的占位符 (可选)
    // ...

    // 调用 API
    const result = await analyzeText(text);
    
    if (result) {
        const badge = createBadge(result);
        // 插入到文本下方或旁边 (User Name 旁边通常比较显眼，或者 action bar 上方)
        // 这里我们选择插入到文本内容的后面
        textNode.appendChild(badge); 
    }
}

// 5. 监听页面变动 (MutationObserver)
// 因为 Twitter 是无限滚动，必须监听 DOM 变化
const observer = new MutationObserver((mutations) => {
    for (const mutation of mutations) {
        for (const node of mutation.addedNodes) {
            if (node.nodeType === 1) { // 元素节点
                // 查找所有新出现的 article 标签 (推文容器)
                const tweets = node.querySelectorAll('article[data-testid="tweet"]');
                tweets.forEach(tweet => {
                    // 加上标记防止重复处理 DOM
                    if (!tweet.dataset.aiProcessed) {
                        tweet.dataset.aiProcessed = "true";
                        processTweet(tweet);
                    }
                });
            }
        }
    }
});

// 启动监听
observer.observe(document.body, { childList: true, subtree: true });
console.log("Rhetoric Lens 已启动...");

```

---

### 如何安装与运行

1. **准备环境:**
* 确保你的 Ollama 正在运行，并且你的模型 (`xiuci-pro`) 已经加载。
* **关键:** 解决 CORS 跨域问题。如果是本地 Ollama，需要设置环境变量。
* **Mac/Linux:** `launchctl setenv OLLAMA_ORIGINS "*"` 然后重启 Ollama。
* **Windows:** 环境变量设置 `OLLAMA_ORIGINS` 值为 `*`。




2. **加载插件:**
* 打开 Chrome 浏览器，输入 `chrome://extensions/`。
* 打开右上角的 **"开发者模式" (Developer mode)**。
* 点击左上角的 **"加载已解压的扩展程序" (Load unpacked)**。
* 选择你的 `rhetoric-detector-extension` 文件夹。


3. **测试:**
* 打开 Twitter (x.com)。
* 刷新页面。
* 你应该能看到推文内容旁边慢慢出现绿色、黄色或红色的标签。
* 鼠标放上去，就能看到你训练出的模型给出的犀利评价。



### 进阶优化建议 (展示技术实力用)

1. **Debounce (防抖):** 目前代码一刷出来就请求，如果页面推文多，会瞬间并发几十个请求给 Mac Mini。建议加个**任务队列**，比如同一时间只允许 3 个请求并行，或者用户停止滚动 0.5秒后再分析视口内的推文。
2. **Icon 交互:** 不要默认全部分析（太费电/费钱）。可以在每条推文旁加个小图标（放大镜），用户**点击后**才触发分析。这样商业逻辑更合理。
3. **Prompt 缓存:** 利用 Chrome 的 `local.storage`，如果某段文字已经分析过，直接读缓存，不再请求 API。

这一套跑通，你的“全栈 AI 工程师”人设就立住了。需要我帮你写“点击触发模式”的代码吗？这样演示效果更可控。